{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MOdel selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model hyper parameter tuning\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score,roc_curve\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(folder, samp = False, lof=False):\n",
    "    df = pd.read_csv(folder)\n",
    "    if samp==True:\n",
    "        df = df.sample(frac=0.5, replace=False, random_state=42).reset_index(drop=True)\n",
    "    if lof==True:\n",
    "        #df_new = pd.DataFrame(scaler.fit_transform(df_new))\n",
    "        df = filter_lof(df)\n",
    "        #df_new = scaler.inverse_transform(df_new)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lof(df, k=20) :\n",
    "    lof = LocalOutlierFactor(n_neighbors=k)\n",
    "    scaler = StandardScaler()\n",
    "    df2 = pd.DataFrame.copy(df)\n",
    "    df2 = df2.drop(columns = ['churn'])\n",
    "    df2 = pd.DataFrame(scaler.fit_transform(df2))\n",
    "    df2[\"_lof\"] = lof.fit_predict(df2)\n",
    "    df2 = df2[df2[\"_lof\"]>0].drop(columns=\"_lof\")#.reset_index(drop=True)\n",
    "    df2 = pd.DataFrame(scaler.inverse_transform(df2))\n",
    "    df2['churn'] = df['churn']\n",
    "    return df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churn_prediction(algorithm,training_x,testing_x,\n",
    "                             training_y,testing_y,cols,cf,threshold_plot) :\n",
    "    \n",
    "    #model\n",
    "    algorithm.fit(training_x,training_y)\n",
    "    predictions   = algorithm.predict(testing_x)\n",
    "    probabilities = algorithm.predict_proba(testing_x)\n",
    "    #coeffs\n",
    "    if   cf == \"coefficients\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n",
    "    elif cf == \"features\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n",
    "        \n",
    "    column_df     = pd.DataFrame(cols)\n",
    "    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    #print (algorithm)\n",
    "    #print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n",
    "    #print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n",
    "    return accuracy_score(testing_y,predictions)\n",
    "    #confusion matrix\n",
    "    conf_matrix = confusion_matrix(testing_y,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(filename, algo, seed, before) :\n",
    "    X, Y = readXY(filename, before)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "    rfe_algo = algo\n",
    "    \n",
    "    accuracy = churn_prediction(rfe_algo, x_train, x_test, y_train, y_test, x_train.columns,\"features\",threshold_plot = False)\n",
    "    return rfe_algo, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXY(filename,before=True) :\n",
    "    df = read_file(filename, samp=False, lof=False)\n",
    "    churn(df,before)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    X = df.drop(columns=['churn'], axis=1)\n",
    "    Y = df[['churn']]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churn_validation(algorithm,testing_x,\n",
    "                             testing_y,cols) :\n",
    "    #model\n",
    "    predictions   = algorithm.predict(testing_x)\n",
    "    probabilities = algorithm.predict_proba(testing_x)\n",
    "    \n",
    "    #print (algorithm)\n",
    "    #print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n",
    "    #print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n",
    "    return accuracy_score(testing_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_raw_data(model, before) :\n",
    "    X, Y = readXY('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv', before)\n",
    "    acc = churn_validation(model, X,Y, X.columns)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# churn label anonymized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/dataprivacy/churn-anonymized/v1/alex2/k10_e10_lof/telecom_churn_data_pre_nodates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093596432496621"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['churn']<0.5])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980889808898089"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['churn']<0.5])/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# churn label created after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_churned(_x):\n",
    "    if ((_x.total_ic_mou_9 == 0) & (_x.total_og_mou_9 == 0) & (_x.vol_2g_mb_9 == 0) & (_x.vol_3g_mb_9 == 0)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_churn = df.drop(['churn'],axis = 1)\n",
    "data_churn['churn'] = data_churn.apply(is_churned, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252896069935194"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_churn[data_churn['churn']<0.5])/len(data_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churn(df, before=True):\n",
    "    if before == True:\n",
    "        df.loc[df['churn'] > 0.5, 'churn'] = 1\n",
    "        df.loc[df['churn'] <= 0.5, 'churn'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [RandomForestClassifier(n_jobs=-1,\n",
    "                                bootstrap=True,\n",
    "                                max_depth=10,\n",
    "                                min_samples_leaf=50,\n",
    "                                min_samples_split=50,\n",
    "                                n_estimators=60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attila1\n",
      "c3_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c20_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c10_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c3_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c10_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c5_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c5_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c20_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "attila2\n",
      "c3_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c20_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c10_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c3_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c10_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c5_e10\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c5_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "c20_e1\n",
      "0\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "2\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n",
      "3\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=50,\n",
      "                       n_estimators=60, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(columns = ['accuracy'])\n",
    "before = True\n",
    "\n",
    "for algo_anon in ['attila1', 'attila2']:\n",
    "    print(algo_anon)\n",
    "    if algo_anon=='alex1b' or 'alex2':\n",
    "        df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv', lof=True)\n",
    "        df_original = df_original.dropna().reset_index(drop=True)\n",
    "    if algo_anon=='attila1' or 'attila2':\n",
    "        df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv')\n",
    "    for file in os.listdir('/data/dataprivacy/churn-anonymized/v1/'+algo_anon):\n",
    "        if file.startswith('c') or file.startswith('k'):\n",
    "            print(file)\n",
    "            #file beolvasas\n",
    "            folder = '/data/dataprivacy/churn-anonymized/v1/'+algo_anon+'/'+file+'/'+'telecom_churn_data_pre_nodates.csv'\n",
    "            #df = read_file(folder)\n",
    "            #df = df.dropna().reset_index(drop=True)\n",
    "            ultim_best_scores = 0\n",
    "            df_ultim_best = pd.DataFrame()\n",
    "            for seed in [0,1,2,3]:\n",
    "                print(seed)\n",
    "                ultim_best_scores = 0\n",
    "                df_ultim_best = pd.DataFrame()\n",
    "                for algo in algos:\n",
    "                    print(algo)\n",
    "                    model, accuracy_train =  train_model(folder, algo, seed, before)\n",
    "                    if accuracy_train > ultim_best_scores:\n",
    "                        ultim_best_scores = accuracy_train\n",
    "                        best_model = model \n",
    "    \n",
    "                    ###\n",
    "                df_eval.loc[algo_anon+'_'+file+'_'+str(seed)] = ultim_best_scores\n",
    "                df_eval.loc[algo_anon+'_'+file+'_'+str(seed)+'_original'] = validate_with_raw_data(best_model,before=True)\n",
    "                df_eval.to_csv('churn_eval_total_class_attila.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
