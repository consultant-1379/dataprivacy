{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in /opt/conda/lib/python3.7/site-packages (0.8.27)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.15.0)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (0.29.6)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (0.24.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.19.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from hdbscan) (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->hdbscan) (2.1.0)\n",
      "Requirement already satisfied: fa_kit in /opt/conda/lib/python3.7/site-packages (0.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fa_kit) (3.0.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fa_kit) (1.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fa_kit) (1.19.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fa_kit) (1.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fa_kit) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fa_kit) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fa_kit) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fa_kit) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->fa_kit) (2020.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fa_kit) (1.15.0)\n",
      "Requirement already satisfied: kneed in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kneed) (3.0.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from kneed) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /opt/conda/lib/python3.7/site-packages (from kneed) (1.19.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->kneed) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "#!pip install scikit-learn==0.24.0\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import DBSCAN\n",
    "!pip install hdbscan\n",
    "!pip install fa_kit\n",
    "!pip install kneed\n",
    "from fa_kit.rotation import VarimaxRotatorPython\n",
    "\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import seaborn as sns; sns.set();\n",
    "from seaborn import heatmap\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "import random as random\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import itertools as it\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def read_file(folder):\n",
    "    df = pd.DataFrame()\n",
    "    path = folder+'/'\n",
    "    df_new = pd.read_csv(path+'benign_traffic.csv')\n",
    "    df_new['label'] = 'benign_traffic'\n",
    "    df = pd.concat([df,df_new], ignore_index=True)\n",
    "    \n",
    "    directory = os.fsencode(path+'gafgyt_attacks')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"): \n",
    "            df_new = pd.read_csv(path+'gafgyt_attacks'+'/'+filename)\n",
    "            filename=filename[:-4] \n",
    "            df_new['label'] = 'gafgyt_'+filename\n",
    "            df = pd.concat([df,df_new], ignore_index=True)\n",
    "    directory = os.fsencode(path+'mirai_attacks')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"): \n",
    "            df_new = pd.read_csv(path+'mirai_attacks'+'/'+filename)\n",
    "            filename=filename[:-4] \n",
    "            df_new['label'] = 'mirai_'+filename\n",
    "            df = pd.concat([df,df_new], ignore_index=True)\n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(folder, samp = False, lof=False):\n",
    "    df = pd.DataFrame()\n",
    "    path = folder+'/'\n",
    "    df_new = pd.read_csv(path+'benign_traffic.csv')\n",
    "    df_new['label'] = 'benign_traffic'\n",
    "    if samp==True:\n",
    "        df_new = df_new.sample(frac=0.5, replace=False, random_state=42).reset_index(drop=True)\n",
    "    if lof==True:\n",
    "        #df_new = pd.DataFrame(scaler.fit_transform(df_new))\n",
    "        df_new = filter_lof(df_new)\n",
    "        #df_new = scaler.inverse_transform(df_new)\n",
    "    df = pd.concat([df,df_new], ignore_index=True)\n",
    "    \n",
    "    directory = os.fsencode(path+'gafgyt_attacks')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"): \n",
    "            df_new = pd.read_csv(path+'gafgyt_attacks'+'/'+filename)\n",
    "            filename=filename[:-4] \n",
    "            df_new['label'] = 'gafgyt_'+filename\n",
    "            if samp==True:\n",
    "                df_new = df_new.sample(frac=0.5, replace=False, random_state=42).reset_index(drop=True)\n",
    "            if lof==True:\n",
    "                #df_new = pd.DataFrame(scaler.fit_transform(df_new))\n",
    "                df_new = filter_lof(df_new)\n",
    "                #df_new = scaler.inverse_transform(df_new)\n",
    "            df = pd.concat([df,df_new], ignore_index=True)\n",
    "    directory = os.fsencode(path+'mirai_attacks')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"): \n",
    "            df_new = pd.read_csv(path+'mirai_attacks'+'/'+filename)\n",
    "            filename=filename[:-4] \n",
    "            df_new['label'] = 'mirai_'+filename\n",
    "            if samp==True:\n",
    "                df_new = df_new.sample(frac=0.5, replace=False, random_state=42).reset_index(drop=True)\n",
    "            if lof==True:\n",
    "                #df_new = pd.DataFrame(scaler.fit_transform(df_new))\n",
    "                df_new = filter_lof(df_new)\n",
    "                #df_new = scaler.inverse_transform(df_new)\n",
    "            df = pd.concat([df,df_new], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_func(rate, data):    \n",
    "    df_wo_label = data.drop(columns = ['label'])\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(df_wo_label)\n",
    "    pca = PCA(n_components=rate, random_state=0)\n",
    "    pca_comp = pca.fit(data_scaled).components_\n",
    "    return pca_comp, data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEts transform our original dataset to lower dimensional\n",
    "def decrease_dim(components, data_scaled):\n",
    "    varimax = VarimaxRotatorPython()\n",
    "    rotated_weights = varimax.rotate(components.T)\n",
    "    df_lowdim = pd.DataFrame(np.dot(data_scaled, rotated_weights))\n",
    "    #df_lowdim[\"label\"] = df[\"label\"]\n",
    "    rotated_data = np.dot(data_scaled, rotated_weights)\n",
    "    return df_lowdim, rotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "def adj_rand(data):\n",
    "    tab = pd.crosstab(data['label'], data['cluster_label'])\n",
    "    df_tab = pd.DataFrame(tab)\n",
    "    a = list(df_tab.sum(axis=1))\n",
    "    b = list(df_tab.sum(axis=0))\n",
    "    n = df_tab.values.tolist()\n",
    "    sum_n = 0\n",
    "    for i in range(len(n)):\n",
    "        for j in range(len(n[0])):\n",
    "            sum_n += scipy.special.comb(n[i][j],2)\n",
    "    sum_a = 0\n",
    "    for k in range(len(a)):\n",
    "        sum_a += scipy.special.comb(a[k],2)\n",
    "    sum_b = 0\n",
    "    for l in range(len(b)):\n",
    "        sum_b += scipy.special.comb(b[l],2)\n",
    "    \n",
    "    ari = (sum_n - sum_a*sum_b/scipy.special.comb(sum(a),2))/(0.5*(sum_a+sum_b)-sum_a*sum_b/scipy.special.comb(sum(a),2))\n",
    "    return(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evall(df_cl):\n",
    "    sc = []\n",
    "    sc.append(metrics.rand_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(adj_rand(df_cl))\n",
    "    sc.append(metrics.mutual_info_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(metrics.adjusted_mutual_info_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(metrics.homogeneity_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(metrics.completeness_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(metrics.v_measure_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    sc.append(metrics.fowlkes_mallows_score(df_cl['label'], df_cl['cluster_label']))\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/data/dataprivacy/detection_of_IoT_botnet_attacks-anonymized/Philips_B120N10_Baby_Monitor/alex2/baby_k10_e1_lof'\n",
    "#folder = '/data/dataprivacy/detection_of_IoT_botnet_attacks-anonymized/SimpleHome_XCS7_1003_WHT_Security_Camera/attila1/c3_e10'\n",
    "df = read_file(folder)\n",
    "df = df_original.sample(n=100000, replace=False, random_state=0)#.reset_index(drop=True)\n",
    "#df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lof(df, k=20) :\n",
    "    lof = LocalOutlierFactor(n_neighbors=k)\n",
    "    scaler = StandardScaler()\n",
    "    df2 = pd.DataFrame.copy(df)\n",
    "    df2 = df2.drop(columns = ['label'])\n",
    "    df2 = pd.DataFrame(scaler.fit_transform(df2))\n",
    "    df2[\"_lof\"] = lof.fit_predict(df2)\n",
    "    df2 = df2[df2[\"_lof\"]>0].drop(columns=\"_lof\")#.reset_index(drop=True)\n",
    "    df2 = pd.DataFrame(scaler.inverse_transform(df2))\n",
    "    df2['label'] = df['label']\n",
    "    return df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(low_data, num_cl):\n",
    "    low_data_2 = low_data.copy()\n",
    "    kmeans = KMeans(init=\"random\",n_clusters=num_cl,n_init=10,max_iter=200,random_state=43)\n",
    "    kmeans.fit(low_data_2)\n",
    "    low_data_2[\"cluster_label\"] = kmeans.labels_\n",
    "    low_data_2[\"label\"] = df[\"label\"]\n",
    "    return low_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(low_data, num_cl):\n",
    "    low_data_2 = low_data.copy()\n",
    "    mini_kmeans = MiniBatchKMeans(init=\"random\",n_clusters=num_cl,n_init=10,max_iter=200,random_state=43)\n",
    "    mini_kmeans.fit(low_data_2)\n",
    "    low_data_2[\"cluster_label\"] = mini_kmeans.labels_\n",
    "    low_data_2[\"label\"] = df[\"label\"]\n",
    "    return low_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shift(low_data):\n",
    "    low_data_2 = low_data.copy()\n",
    "    mean_sh = MeanShift().fit(low_data_2)\n",
    "    low_data_2[\"cluster_label\"] = mean_sh.labels_\n",
    "    low_data_2[\"label\"] = reduced_label\n",
    "    return low_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optics(low_data):\n",
    "    low_data_2 = low_data.copy()\n",
    "    opti = OPTICS().fit(low_data_2)\n",
    "    low_data_2[\"cluster_label\"] = opti.labels_\n",
    "    low_data_2[\"label\"] = reduced_label\n",
    "    return low_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(low_data, ep, min_samp):\n",
    "    low_data_2 = low_data.copy()\n",
    "    dbsc = DBSCAN(eps=ep, min_samples=min_samp).fit(low_data_2)\n",
    "    low_data_2[\"cluster_label\"] = dbsc.labels_\n",
    "    low_data_2[\"label\"] = reduced_label\n",
    "    return low_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.sample(n=100000)\n",
    "reduced_label = df_reduced['label'].reset_index(drop=True)\n",
    "comp, df_scaled = pca_func(0.7, df_reduced)\n",
    "df_low, np_low = decrease_dim(comp, df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9081935389353893,\n",
       "  0.5725643034768708,\n",
       "  1.7076800468607916,\n",
       "  0.7596554061716501,\n",
       "  0.7584602111532377,\n",
       "  0.7616596325818332,\n",
       "  0.7600565549298826,\n",
       "  0.6252566422872781],\n",
       " [0.9090739311393113,\n",
       "  0.5775966605445773,\n",
       "  1.717163139704883,\n",
       "  0.7645584847554555,\n",
       "  0.7626720941778928,\n",
       "  0.7671809190968817,\n",
       "  0.7649198623709206,\n",
       "  0.6298605609915215],\n",
       " [0.9098312971129712,\n",
       "  0.5822506636869994,\n",
       "  1.7238507826399327,\n",
       "  0.7693890136370647,\n",
       "  0.7656423877536477,\n",
       "  0.7737515020454022,\n",
       "  0.7696755865795288,\n",
       "  0.6341765113233925],\n",
       " [0.8968094640946409,\n",
       "  0.5449844603476173,\n",
       "  1.595296795586191,\n",
       "  0.7358106787276452,\n",
       "  0.708545577174517,\n",
       "  0.7658832944021328,\n",
       "  0.7360995587399127,\n",
       "  0.6065291289845909],\n",
       " [0.8947756793567936,\n",
       "  0.5458167235394826,\n",
       "  1.5504960882356278,\n",
       "  0.7308593582362228,\n",
       "  0.6886474973091542,\n",
       "  0.7791067714589555,\n",
       "  0.7310895832067802,\n",
       "  0.6098601071385136],\n",
       " [0.8952224556245563,\n",
       "  0.5487974247746159,\n",
       "  1.5533347459592046,\n",
       "  0.7333073256065497,\n",
       "  0.6899082773600623,\n",
       "  0.7830238230212072,\n",
       "  0.7335227696274885,\n",
       "  0.6127651968853448],\n",
       " [0.8458736835368353,\n",
       "  0.43036979345143256,\n",
       "  1.3380605123787943,\n",
       "  0.6662589203787633,\n",
       "  0.5942949679714566,\n",
       "  0.7587295581899807,\n",
       "  0.6665203028695303,\n",
       "  0.533034497722048],\n",
       " [0.8477834476344763,\n",
       "  0.44145290233779527,\n",
       "  1.3402811402865604,\n",
       "  0.6730735567235571,\n",
       "  0.5952812522083154,\n",
       "  0.7748739400899901,\n",
       "  0.6733075668408441,\n",
       "  0.5441175751842386]]"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dbscan = []\n",
    "for j in [0.18,0.2,0.22,0.25,0.3,0.35,0.4,0.5]:\n",
    "    df_dbscan = dbscan(df_low, j, 5)\n",
    "    metrics_dbscan = evall(df_dbscan)\n",
    "    eval_dbscan.append(metrics_dbscan)\n",
    "eval_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9101824386243862,\n",
       "  0.5840075335335431,\n",
       "  1.731209411718691,\n",
       "  0.7692871761350932,\n",
       "  0.7689106975140932,\n",
       "  0.7708568811384351,\n",
       "  0.7698825593904114,\n",
       "  0.6357457505888556],\n",
       " [0.9098312971129712,\n",
       "  0.5822506636869994,\n",
       "  1.7238507826399327,\n",
       "  0.7693890136370647,\n",
       "  0.7656423877536477,\n",
       "  0.7737515020454022,\n",
       "  0.7696755865795288,\n",
       "  0.6341765113233925],\n",
       " [0.9091912619126191,\n",
       "  0.5785958353478443,\n",
       "  1.7137446525617779,\n",
       "  0.7663523091637212,\n",
       "  0.7611537848873731,\n",
       "  0.7719856892713004,\n",
       "  0.7665314724091745,\n",
       "  0.6308284591857392],\n",
       " [0.9087333721337213,\n",
       "  0.5759008865486979,\n",
       "  1.7087180851850665,\n",
       "  0.7636931507462328,\n",
       "  0.7589212522997113,\n",
       "  0.7688878935446882,\n",
       "  0.7638720643009572,\n",
       "  0.628348686728752],\n",
       " [0.9141379257792578,\n",
       "  0.5911574344616732,\n",
       "  1.7702650376686504,\n",
       "  0.7796420091525377,\n",
       "  0.7862571192628173,\n",
       "  0.7733671680587154,\n",
       "  0.7797588773570178,\n",
       "  0.6399522969529821],\n",
       " [0.9133131785317853,\n",
       "  0.5869293256513347,\n",
       "  1.7599976633475465,\n",
       "  0.7757371067299358,\n",
       "  0.7816969003214007,\n",
       "  0.7700464938418267,\n",
       "  0.7758279617669831,\n",
       "  0.6361803413767468]]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dbscan = []\n",
    "#for i in [3,4,5,6,9,10, 11, 12]:\n",
    "for i in [3,5,8,10,15,20]:\n",
    "    df_dbscan = dbscan(df_low, 0.22, i)\n",
    "    metrics_dbscan = evall(df_dbscan)\n",
    "    eval_dbscan.append(metrics_dbscan)\n",
    "eval_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "def adj_rand_2(label_pred, label_true):\n",
    "    tab = pd.crosstab(label_true, label_pred)\n",
    "    df_tab = pd.DataFrame(tab)\n",
    "    a = list(df_tab.sum(axis=1))\n",
    "    b = list(df_tab.sum(axis=0))\n",
    "    n = df_tab.values.tolist()\n",
    "    sum_n = 0\n",
    "    for i in range(len(n)):\n",
    "        for j in range(len(n[0])):\n",
    "            sum_n += scipy.special.comb(n[i][j],2)\n",
    "    sum_a = 0\n",
    "    for k in range(len(a)):\n",
    "        sum_a += scipy.special.comb(a[k],2)\n",
    "    sum_b = 0\n",
    "    for l in range(len(b)):\n",
    "        sum_b += scipy.special.comb(b[l],2)\n",
    "    \n",
    "    ari = (sum_n - sum_a*sum_b/scipy.special.comb(sum(a),2))/(0.5*(sum_a+sum_b)-sum_a*sum_b/scipy.special.comb(sum(a),2))\n",
    "    return(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evall_2(label_pred, label_true):\n",
    "    sc = []\n",
    "    sc.append(metrics.rand_score(label_true, label_pred))\n",
    "    sc.append(adj_rand_2(label_true, label_pred))\n",
    "    sc.append(metrics.mutual_info_score(label_true, label_pred))\n",
    "    sc.append(metrics.adjusted_mutual_info_score(label_true, label_pred))\n",
    "    sc.append(metrics.homogeneity_score(label_true, label_pred))\n",
    "    sc.append(metrics.completeness_score(label_true, label_pred))\n",
    "    sc.append(metrics.v_measure_score(label_true, label_pred))\n",
    "    sc.append(metrics.fowlkes_mallows_score(label_true, label_pred))\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in original data (wo anonymization)\n",
    "def read_file_o(dfs, device):\n",
    "    df = pd.DataFrame()\n",
    "    for i in dfs:\n",
    "        #df_new = pd.read_csv(i+'.csv')\n",
    "        #df_new = pd.read_csv('./Simple_home_1003_sec_cam/'+i+'.csv')\n",
    "        df_new = pd.read_csv('./'+device+'/'+i+'.csv')\n",
    "        df_new['label'] = i\n",
    "        df = pd.concat([df,df_new], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['benign_traffic', 'bashlite_combo', 'bashlite_junk', 'bashlite_scan', 'bashlite_tcp', 'bashlite_udp',\n",
    "       'mirai_ack', 'mirai_scan', 'mirai_syn', 'mirai_udp', 'mirai_udpplain']\n",
    "df_original = read_file_o(files)\n",
    "df_original = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleHome_XCS7_1003_WHT_Security_Camera\n",
      "alex1b\n",
      "k10_e10_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k10_e1_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k20_e5_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k20_e1_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k50_e5_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k50_e1_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "2\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "3\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "k20_e10_lof\n",
      "0\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n",
      "1\n",
      "optics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/cluster/_optics.py:803: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans\n",
      "minibatch\n",
      "dbscan\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(columns = ['rand_score', 'adjusted_rand_score', 'mutual_info_score', 'adjusted_mutual_info_score', \n",
    "                                  'homogeneity_score', 'completeness_score', 'v_measure_score', 'fowlkes_mallows_score'])\n",
    "#for device in ['SimpleHome_XCS7_1003_WHT_Security_Camera', 'Philips_B120N10_Baby_Monitor']:\n",
    "for device in ['SimpleHome_XCS7_1003_WHT_Security_Camera']:\n",
    "    print(device)\n",
    "    #original file beolvasas\n",
    "    files = ['benign_traffic', 'bashlite_combo', 'bashlite_junk', 'bashlite_scan', 'bashlite_tcp', 'bashlite_udp', 'mirai_ack', 'mirai_scan', 'mirai_syn', 'mirai_udp', 'mirai_udpplain']\n",
    "    #scaling\n",
    "    #df_o_wo_label = df_original.drop(columns = ['label'])\n",
    "    #scaler = StandardScaler()\n",
    "    #data_o_scaled = scaler.fit_transform(df_o_wo_label)\n",
    "    #for algo_anon in ['alex2', 'attila1', 'attila2']:\n",
    "    for algo_anon in ['alex1b']:\n",
    "        print(algo_anon)\n",
    "        if algo_anon=='alex1b' or 'alex2':\n",
    "            df_original = read_file('/data/dataprivacy/detection_of_IoT_botnet_attacks/'+device, samp=True, lof=True)\n",
    "        if algo_anon=='attila1' or 'attila2':\n",
    "            df_original = read_file('/data/dataprivacy/detection_of_IoT_botnet_attacks/'+device, samp=True)\n",
    "        #scaling\n",
    "        df_o_wo_label = df_original.drop(columns = ['label'])\n",
    "        scaler = StandardScaler()\n",
    "        data_o_scaled = scaler.fit_transform(df_o_wo_label)\n",
    "        for file in os.listdir('/data/dataprivacy/detection_of_IoT_botnet_attacks-anonymized/'+device+'/'+algo_anon):\n",
    "            if file.startswith('c') or file.startswith('k'):\n",
    "                print(file)\n",
    "                #file beolvasas\n",
    "                folder = '/data/dataprivacy/detection_of_IoT_botnet_attacks-anonymized/'+device+'/'+algo_anon+'/'+file\n",
    "                df = read_file(folder)\n",
    "                df = df.dropna().reset_index(drop=True)\n",
    "                for seed in [0,1,2,3]:\n",
    "                    print(seed)\n",
    "                    df_reduced = df.sample(n=100000,replace=False, random_state=seed)\n",
    "                    df_reduced2 = df_reduced.copy()\n",
    "                    reduced_label = df_reduced['label'].reset_index(drop=True)\n",
    "                    comp, df_scaled = pca_func(0.7, df_reduced)\n",
    "                    df_low, np_low = decrease_dim(comp, df_scaled)\n",
    "                    df_reduced2 = df_reduced.reset_index(drop=True) \n",
    "                    ultim_best_scores = [0,0,0,0,0,0,0,0]\n",
    "                    df_ultim_best = pd.DataFrame()\n",
    "                    for algo in ['optics', 'kmeans', 'minibatch', 'dbscan']:\n",
    "                        print(algo)\n",
    "                        if algo is 'meanshift':\n",
    "                            df_meanshift = mean_shift(df_low)\n",
    "                            metrics_meanshift = evall(df_meanshift)\n",
    "                            if metrics_meanshift[6]>ultim_best_scores[6]:\n",
    "                                ultim_best_scores = metrics_meanshift\n",
    "                                df_ultim_best = df_meanshift\n",
    "                        if algo is 'optics':\n",
    "                            df_optics = optics(df_low)\n",
    "                            metrics_optics = evall(df_optics)\n",
    "                            if metrics_optics[6]>ultim_best_scores[6]:\n",
    "                                ultim_best_scores = metrics_optics\n",
    "                                df_ultim_best = df_optics\n",
    "                        if algo is 'kmeans':\n",
    "                            eval_kmeans = [0,0,0,0,0,0,0,0]\n",
    "                            df_best = pd.DataFrame()\n",
    "                            for k in range(7,15):\n",
    "                                df_kmeans = kmeans(df_low, k)\n",
    "                                metrics_kmeans = evall(df_kmeans)\n",
    "                                if metrics_kmeans[6]>eval_kmeans[6]:\n",
    "                                    eval_kmeans=metrics_kmeans\n",
    "                                    df_best_kmeans = df_kmeans\n",
    "                            if eval_kmeans[6]>ultim_best_scores[6]:\n",
    "                                ultim_best_scores = eval_kmeans\n",
    "                                df_ultim_best = df_best_kmeans\n",
    "                        if algo is 'minibatch':\n",
    "                            eval_minibatch = [0,0,0,0,0,0,0,0]\n",
    "                            df_best = pd.DataFrame()\n",
    "                            for k in range(7,15):\n",
    "                                df_minibatch = minibatch(df_low, k)\n",
    "                                metrics_minibatch = evall(df_minibatch)\n",
    "                                if metrics_minibatch[6]>eval_minibatch[6]:\n",
    "                                    eval_minibatch=metrics_minibatch\n",
    "                                    df_best_minibatch = df_minibatch\n",
    "                            if eval_minibatch[6]>ultim_best_scores[6]:\n",
    "                                ultim_best_scores = eval_minibatch\n",
    "                                df_ultim_best = df_best_minibatch\n",
    "                        if algo is 'dbscan':\n",
    "                            eval_dbscan = [0,0,0,0,0,0,0,0]\n",
    "                            df_best = pd.DataFrame()\n",
    "                            for ep in [0.18,0.2,0.22,0.25,0.3,0.4,0.5]:\n",
    "                                for min_sam in [3,5,8,10,12]:\n",
    "                                    df_dbscan = dbscan(df_low, ep, min_sam)\n",
    "                                    metrics_dbscan = evall(df_dbscan)\n",
    "                                    if metrics_dbscan[6]>eval_dbscan[6]:\n",
    "                                        eval_dbscan=metrics_dbscan\n",
    "                                        df_best_dbscan = df_dbscan\n",
    "                            if eval_dbscan[6]>ultim_best_scores[6]:\n",
    "                                ultim_best_scores = eval_dbscan\n",
    "                                df_ultim_best = df_best_dbscan\n",
    "                    df_reduced2[\"cluster_label\"] = df_ultim_best[\"cluster_label\"]\n",
    "                    ###\n",
    "                    df_eval.loc[device+'_'+algo_anon+'_'+file+'_'+str(seed)] = evall(df_ultim_best)  \n",
    "                    y = df_reduced2['cluster_label'][:190000]\n",
    "                    X = df_low.iloc[:190000,:]\n",
    "                    dt = OneVsRestClassifier(XGBClassifier(random_state=4, max_depth=8), n_jobs=7)\n",
    "                    dt.fit(X, y)  \n",
    "                    test_label = dt.predict(df_low.iloc[90000:,:])\n",
    "                    true_label = df_reduced2['cluster_label'][90000:]    \n",
    "                    #apply same tree to original\n",
    "                    #decrease dim\n",
    "                    varimax = VarimaxRotatorPython()\n",
    "                    rotated_weights = varimax.rotate(comp.T)\n",
    "                    df_o_lowdim = pd.DataFrame(np.dot(data_o_scaled, rotated_weights))\n",
    "                    #test original\n",
    "                    test_label_o = dt.predict(df_o_lowdim)\n",
    "                    true_label_o = df_original['label']\n",
    "                    ###\n",
    "                    df_eval.loc[device+'_'+algo_anon+'_'+file+'_'+str(seed)+'_original'] = evall_2(test_label_o, true_label_o)  \n",
    "                    df_eval.to_csv('eval_total_'+device+'.csv')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1         2         3         4  cluster_label  \\\n",
      "0       2.753317 -0.648823 -0.251951 -0.005992 -5.147781              6   \n",
      "1      -2.246141 -3.187886 -2.022540  0.859386 -5.003501              6   \n",
      "2       2.757108 -0.626852 -0.252058 -0.005805 -5.143632              6   \n",
      "3       2.751079 -0.639435 -0.251551 -0.005815 -5.129953              6   \n",
      "4       2.757136 -0.626673 -0.252192 -0.005809 -5.143990              6   \n",
      "...          ...       ...       ...       ...       ...            ...   \n",
      "396037 -4.715749  6.540347 -0.266300  0.015813  1.186763              4   \n",
      "396038 -4.642063  6.098272 -0.262651  0.011855  0.343731              4   \n",
      "396039 -4.281696  5.677139 -0.299778  0.015696  0.333500              4   \n",
      "396040  6.934503  3.852830  0.300300 -0.056403  0.548733              7   \n",
      "396041 -4.387097  5.896750 -0.276218  0.011317 -0.622355              4   \n",
      "\n",
      "                 label  \n",
      "0       benign_traffic  \n",
      "1       benign_traffic  \n",
      "2       benign_traffic  \n",
      "3       benign_traffic  \n",
      "4       benign_traffic  \n",
      "...                ...  \n",
      "396037       mirai_udp  \n",
      "396038       mirai_udp  \n",
      "396039       mirai_udp  \n",
      "396040       mirai_udp  \n",
      "396041       mirai_udp  \n",
      "\n",
      "[396042 rows x 7 columns]\n",
      "[0.8359080484442281, 0.38619385005775125, 1.2348065469207405, 0.6165297378320281, 0.5561964712681126, 0.6915875382891661, 0.6165466866431699, 0.49008614442978043]\n"
     ]
    }
   ],
   "source": [
    "folder = '/data/dataprivacy/detection_of_IoT_botnet_attacks-anonymized/'+'SimpleHome_XCS7_1003_WHT_Security_Camera'+'/'+'alex2'+'/'+'k10_e10_lof'\n",
    "df = read_file(folder)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "comp, df_scaled = pca_func(0.7, df)\n",
    "df_low, np_low = decrease_dim(comp, df_scaled)\n",
    "\n",
    "df_kmeans = kmeans(df_low, 8)\n",
    "print(df_kmeans)\n",
    "print(evall(df_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.sample(n=100000)\n",
    "df_reduced2 = df_reduced.copy()\n",
    "reduced_label = df_reduced['label'].reset_index(drop=True)\n",
    "comp, df_scaled = pca_func(0.7, df_reduced)\n",
    "df_low, np_low = decrease_dim(comp, df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.827229472294723,\n",
       " 0.3943155857846049,\n",
       " 1.2840817877990083,\n",
       " 0.6241371955234212,\n",
       " 0.5747797770717933,\n",
       " 0.6890014119045573,\n",
       " 0.6267288695085382,\n",
       " 0.5102440897307984]"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced2 = df_reduced.reset_index(drop=True)\n",
    "df_dbscan = dbscan(df_low, 0.20, 6)\n",
    "df_reduced2[\"cluster_label\"] = df_dbscan[\"cluster_label\"]\n",
    "evall(df_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992\n"
     ]
    }
   ],
   "source": [
    "y = df_reduced2['cluster_label'][:190000]\n",
    "X = df_low.iloc[:190000,:]\n",
    "dt = OneVsRestClassifier(XGBClassifier(random_state=4, max_depth=8), n_jobs=7)\n",
    "dt.fit(X, y)\n",
    "\n",
    "test_label = dt.predict(df_low.iloc[90000:,:])\n",
    "true_label = df_reduced2['cluster_label'][90000:]\n",
    "\n",
    "print(metrics.accuracy_score(test_label, true_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
