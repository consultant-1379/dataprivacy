{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MOdel selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model hyper parameter tuning\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score,roc_curve\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(folder, samp = False, lof=False):\n",
    "    df = pd.read_csv(folder)\n",
    "    if samp==True:\n",
    "        df = df.sample(frac=0.5, replace=False, random_state=42).reset_index(drop=True)\n",
    "    if lof==True:\n",
    "        #df_new = pd.DataFrame(scaler.fit_transform(df_new))\n",
    "        df = filter_lof(df)\n",
    "        #df_new = scaler.inverse_transform(df_new)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lof(df, k=20) :\n",
    "    lof = LocalOutlierFactor(n_neighbors=k)\n",
    "    df2 = pd.DataFrame.copy(df)\n",
    "    df2[\"_lof\"] = lof.fit_predict(df2)\n",
    "    return df2[df2[\"_lof\"]>0].drop(columns=\"_lof\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lof(df, k=20) :\n",
    "    lof = LocalOutlierFactor(n_neighbors=k)\n",
    "    scaler = StandardScaler()\n",
    "    df2 = pd.DataFrame.copy(df)\n",
    "    df2 = df2.drop(columns = ['churn'])\n",
    "    df2 = pd.DataFrame(scaler.fit_transform(df2))\n",
    "    df2[\"_lof\"] = lof.fit_predict(df2)\n",
    "    df2 = df2[df2[\"_lof\"]>0].drop(columns=\"_lof\")#.reset_index(drop=True)\n",
    "    df2 = pd.DataFrame(scaler.inverse_transform(df2))\n",
    "    df2['churn'] = df['churn']\n",
    "    return df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_attila(df, cluster_size):\n",
    "    firsts = []\n",
    "    files = df['churn'].unique()\n",
    "    to_delete_list = []\n",
    "    for i in range(len(files)):\n",
    "        #last type\n",
    "        if i==len(files)-1:\n",
    "            first = len(df)\n",
    "            firsts.append(first)\n",
    "        else:\n",
    "            first = df.index[df['churn']==files[i+1]].tolist()[0]\n",
    "            firsts.append(first)\n",
    "        #first type\n",
    "        if i==0:\n",
    "            to_delete = first%cluster_size\n",
    "        else:\n",
    "            to_delete = (first-firsts[i-1])%cluster_size\n",
    "        if cluster_size == 3:\n",
    "            to_delete = to_delete-3\n",
    "        #chosing rows to drop\n",
    "        for j in range(to_delete):\n",
    "            to_delete_list.append(first-j-1)\n",
    "    df = df.drop(to_delete_list)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/dataprivacy/churn-anonymized/v1/alex2/k10_e10_lof/telecom_churn_data_pre_nodates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['churn']<0.5])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['churn']<0.5])/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_churned(_x):\n",
    "    if ((_x.total_ic_mou_9 == 0) & (_x.total_og_mou_9 == 0) & (_x.vol_2g_mb_9 == 0) & (_x.vol_3g_mb_9 == 0)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_churn = df.drop(['churn'],axis = 1)\n",
    "data_churn['churn'] = data_churn.apply(is_churned, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_privacy(algos):\n",
    "    df_avg_ident = pd.DataFrame(columns = ['avg_per_10'])\n",
    "    for algo in algos:\n",
    "        print(algo)\n",
    "        if algo=='attila1' or algo=='attila2':\n",
    "            df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv', samp=False, lof=False)\n",
    "            print('attila')\n",
    "        else:\n",
    "            df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv', samp=False, lof=True)\n",
    "            print('nemattila')\n",
    "        for file in os.listdir('/data/dataprivacy/churn-anonymized/v1/'+algo):\n",
    "            if file.startswith('c') or file.startswith('k'):\n",
    "                print(file)\n",
    "                if algo=='attila1' or algo=='attila2':\n",
    "                    if int(file[1])==3 or int(file[1])==5:\n",
    "                        num = int(file[1:2])\n",
    "                    else:\n",
    "                        num = int(file[1:3])\n",
    "                    print(num)\n",
    "                    df_original_cropped = crop_attila(df_original, num)\n",
    "                    df = read_file('/data/dataprivacy/churn-anonymized/v1/'+algo+'/'+file+'/telecom_churn_data_pre_nodates.csv')\n",
    "                    print(len(df_original_cropped))\n",
    "                    print(len(df))\n",
    "                    X = df_original_cropped.iloc[:,:-1]\n",
    "                else:\n",
    "                    df = read_file('/data/dataprivacy/churn-anonymized/v1/'+algo+'/'+file+'/telecom_churn_data_pre_nodates.csv')\n",
    "                    print(len(df_original))\n",
    "                    print(len(df))              \n",
    "                    X = df_original.iloc[:,:-1]\n",
    "                \n",
    "                nbrs_original = NearestNeighbors(n_neighbors=11, algorithm='ball_tree').fit(X)\n",
    "                distances_original, indices_original = nbrs_original.kneighbors(X)\n",
    "                indices_original = indices_original[:,1:]\n",
    "                inds = pd.isnull(df).any(1).to_numpy().nonzero()\n",
    "                df = df.dropna().reset_index(drop=True)\n",
    "                X = X.drop(inds[0]).reset_index(drop=True)\n",
    "                Y = df.iloc[:,:-1]\n",
    "                nbrs = NearestNeighbors(n_neighbors=11, algorithm='ball_tree').fit(Y)\n",
    "                distances, indices = nbrs.kneighbors(Y)\n",
    "                indices = indices[:,1:]\n",
    "                identical = []\n",
    "                for l in range(len(indices)):\n",
    "                    identical.append(len(set(indices_original[l]).intersection(indices[l])))\n",
    "                df_avg_ident.loc[algo+'_'+file] = sum(identical)/len(identical)\n",
    "                df_avg_ident.to_csv('churn_eval_privacy_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attila1\n",
      "attila\n",
      "c3_e1\n",
      "3\n",
      "99999\n",
      "99999\n",
      "c20_e10\n",
      "20\n",
      "99980\n",
      "99980\n",
      "c10_e1\n",
      "10\n",
      "99990\n",
      "99990\n",
      "c3_e10\n",
      "3\n",
      "99999\n",
      "99999\n",
      "c10_e10\n",
      "10\n",
      "99990\n",
      "99990\n",
      "c5_e10\n",
      "5\n",
      "99995\n",
      "99995\n",
      "c5_e1\n",
      "5\n",
      "99995\n",
      "99995\n",
      "c20_e1\n",
      "20\n",
      "99980\n",
      "99980\n",
      "attila2\n",
      "attila\n",
      "c3_e1\n",
      "3\n",
      "99999\n",
      "99999\n",
      "c20_e10\n",
      "20\n",
      "99980\n",
      "99980\n",
      "c10_e1\n",
      "10\n",
      "99990\n",
      "99990\n"
     ]
    }
   ],
   "source": [
    "algos = ['attila1','attila2','alex1b','alex2']\n",
    "eval_privacy(algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(columns = ['original','anonymized-churn','churn-anonymized'])\n",
    "for algo_anon in ['attila1']:#, 'attila2', 'alex1b', 'alex2']:\n",
    "    print(algo_anon)\n",
    "    if algo_anon=='alex1b' or 'alex2':\n",
    "        df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv', lof=True)\n",
    "        df_original = df_original.dropna().reset_index(drop=True)\n",
    "    if algo_anon=='attila1' or 'attila2':\n",
    "        df_original = read_file('/data/dataprivacy/churn/telecom_churn_data_pre_nodates.csv')\n",
    "        if int(file[1])==3 or int(file[1])==5:\n",
    "            num = int(file[1:2])\n",
    "        else:\n",
    "            num = int(file[1:3])\n",
    "        df_original = crop_attila(df_original, num)\n",
    "    print(len(df_original))\n",
    "    for file in os.listdir('/data/dataprivacy/churn-anonymized/v1/'+algo_anon):\n",
    "        print(file)\n",
    "        df = read_file('/data/dataprivacy/churn-anonymized/v1/'+algo_anon+'/'+file+'/'+'telecom_churn_data_pre_nodates.csv')\n",
    "        print(len(df))\n",
    "        similar1=0\n",
    "        similar2=0\n",
    "        \n",
    "        #df_eval.loc[algo_anon+'_'+file] = \n",
    "        #df_eval.to_csv('churn_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
